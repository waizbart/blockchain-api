import json
import os
import re
from typing import Dict, Any, Optional
from app.adapters.llm_adapter import LLMAdapter
from app.models.denuncia import SeveridadeDenuncia


class OpenAIAdapter(LLMAdapter):
    """
    Adapter para integra칞칚o com OpenAI GPT models.
    Implementa a interface LLMAdapter para an치lise de severidade.
    """

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4-turbo"):
        """
        Inicializa o adapter OpenAI.

        Args:
            api_key: Chave da API OpenAI (se n칚o fornecida, busca em vari치vel de ambiente)
            model: Modelo a ser usado (default: gpt-4-turbo)
        """
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = model
        self.client = None

        if self.api_key:
            try:
                import openai
                self.client = openai.OpenAI(api_key=self.api_key)
            except ImportError:
                raise ImportError(
                    "Biblioteca 'openai' n칚o encontrada. Instale com: pip install openai")

    def analyze_severity(self, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analisa severidade usando OpenAI GPT.

        Args:
            prompt: Prompt formatado para an치lise
            context: Contexto adicional da den칰ncia

        Returns:
            Dictionary com resultado da an치lise
        """
        if not self.is_available():
            raise Exception(
                "OpenAI adapter n칚o dispon칤vel - verifique API key")

        try:
            messages = [
                {
                    "role": "system",
                    "content": "Voc칡 칠 um especialista em an치lise de severidade de den칰ncias. SEMPRE responda APENAS em formato JSON v치lido, sem texto adicional antes ou depois do JSON. Sua resposta deve ser um objeto JSON completo."
                },
                {
                    "role": "user",
                    "content": prompt + "\n\nResposta deve ser SOMENTE JSON v치lido, sem explica칞칫es adicionais."
                }
            ]

            params = {
                "model": self.model,
                "messages": messages,
                "temperature": 0.3,
                "max_tokens": 1000
            }

            if self.model in ["gpt-4-turbo", "gpt-3.5-turbo"]:
                params["response_format"] = {"type": "json_object"}

            response = self.client.chat.completions.create(**params)
            content = response.choices[0].message.content.strip()

            if not content.startswith('{'):
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    content = json_match.group()

            result = json.loads(content)
            validated_result = self._validate_and_normalize_response(
                result, context)

            print(f"游댌 VALIDA칂츾O: Iniciando valida칞칚o da resposta")
            print(f"游늶 Resposta recebida: {validated_result}")

            validated_result.update({
                "provider": "openai",
                "model": self.model,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                },
                "method": "llm"
            })

            return validated_result

        except json.JSONDecodeError as e:
            return self._create_fallback_response(f"Erro ao parsear JSON da resposta: {str(e)}", context)
        except Exception as e:
            return self._create_fallback_response(f"Erro na an치lise OpenAI: {str(e)}", context)

    def is_available(self) -> bool:
        """
        Verifica se o servi칞o OpenAI est치 dispon칤vel.
        """
        if not self.api_key or not self.client:
            return False

        try:
            self.client.models.list()
            return True
        except:
            return False

    def get_provider_name(self) -> str:
        """
        Retorna o nome do provedor.
        """
        return f"OpenAI ({self.model})"

    def estimate_cost(self, prompt: str) -> Optional[float]:
        """
        Estima o custo da an치lise baseado no modelo e tamanho do prompt.

        Args:
            prompt: Prompt para estimar custo

        Returns:
            Custo estimado em USD
        """
        pricing = {
            "gpt-4": {"input": 0.03, "output": 0.06},
            "gpt-4-turbo": {"input": 0.01, "output": 0.03},
            "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002}
        }

        if self.model not in pricing:
            return None

        prompt_tokens = len(prompt) / 4
        estimated_completion_tokens = 200

        input_cost = (prompt_tokens / 1000) * pricing[self.model]["input"]
        output_cost = (estimated_completion_tokens / 1000) * \
            pricing[self.model]["output"]

        return round(input_cost + output_cost, 6)

    def _validate_and_normalize_response(self, response: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Valida e normaliza a resposta do LLM.

        Args:
            response: Resposta bruta do LLM
            context: Contexto da den칰ncia

        Returns:
            Resposta validada e normalizada
        """
        required_fields = ["severidade", "justificativa"]

        for field in required_fields:
            if field not in response:
                raise ValueError(
                    f"Campo obrigat칩rio '{field}' n칚o encontrado na resposta")

        severidade_str = str(response["severidade"]).upper()
        valid_severities = ["CRITICA", "ALTA", "MEDIA", "BAIXA"]

        if severidade_str not in valid_severities:
            severity_mapping = {
                "CR칈TICA": "CRITICA",
                "CRITICAL": "CRITICA",
                "HIGH": "ALTA",
                "MEDIUM": "MEDIA",
                "LOW": "BAIXA",
                "MODERADA": "MEDIA"
            }
            severidade_str = severity_mapping.get(severidade_str, "MEDIA")

        try:
            severidade_enum = SeveridadeDenuncia(severidade_str)
        except ValueError:
            severidade_enum = SeveridadeDenuncia.MEDIA

        pontuacao = float(response.get("pontuacao", 5.0))
        pontuacao = max(0.0, min(10.0, pontuacao))

        confianca = float(response.get("confianca", 0.7))
        confianca = max(0.0, min(1.0, confianca))

        return {
            "severidade": severidade_enum,
            "pontuacao": pontuacao,
            "fatores_identificados": response.get("fatores_identificados", []),
            "palavras_chave": response.get("palavras_chave", []),
            "justificativa": response["justificativa"],
            "urgencia": response.get("urgencia", "MEDIA"),
            "recomendacoes": response.get("recomendacoes", []),
            "confianca": confianca,
            "llm_analysis": True
        }

    def _create_fallback_response(self, error_message: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Cria uma resposta de fallback em caso de erro.

        Args:
            error_message: Mensagem de erro
            context: Contexto da den칰ncia

        Returns:
            Resposta de fallback
        """
        return {
            "severidade": SeveridadeDenuncia.MEDIA,
            "pontuacao": 5.0,
            "fatores_identificados": ["An치lise de fallback devido a erro no LLM"],
            "palavras_chave": [],
            "justificativa": f"An치lise autom치tica falhou: {error_message}. Classifica칞칚o padr칚o aplicada.",
            "urgencia": "MEDIA",
            "recomendacoes": ["Revisar manualmente devido a falha na an치lise autom치tica"],
            "confianca": 0.3,
            "llm_analysis": False,
            "error": error_message,
            "provider": "openai",
            "method": "fallback"
        }
